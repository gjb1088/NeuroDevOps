# ai_engine/Dockerfile

FROM ollama/ollama:latest

# Start the Ollama model server
CMD ["ollama", "serve"]
